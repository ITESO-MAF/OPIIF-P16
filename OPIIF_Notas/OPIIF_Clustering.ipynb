{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPIIF_Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a id=\"admin_link\" target=\"_blank\" href=\"#\">Ajenti Administration Interface</a>\n",
       "<p>User: root<br> Password: admin</p>\n",
       "\n",
       "<script type=\"text/Javascript\">\n",
       "document.getElementById('admin_link').href = \"https://\" + window.location.hostname + \":8000\"\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "input_form = \"\"\"\n",
    "<a id=\"admin_link\" target=\"_blank\" href=\"#\">Ajenti Administration Interface</a>\n",
    "<p>User: root<br> Password: admin</p>\n",
    "\"\"\"\n",
    "\n",
    "javascript = \"\"\"\n",
    "<script type=\"text/Javascript\">\n",
    "document.getElementById('admin_link').href = \"https://\" + window.location.hostname + \":8000\"\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "HTML(input_form + javascript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.finance import candlestick, quotes_historical_yahoo, date2num\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Descargar precios Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_data(symbol, days_delta=60):\n",
    "    finish_date = datetime.today()\n",
    "    start_date = finish_date - timedelta(days=days_delta)\n",
    "\n",
    "    stocks_raw = quotes_historical_yahoo(symbol, start_date, finish_date)\n",
    "    stocks_df = pd.DataFrame(stocks_raw, columns=[\"n_date\", \"open\", \"close\", \"high\", \"low\", \"volume\"])\n",
    "    return stocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Configuracion de fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_date(stocks_df):\n",
    "    stocks_df[\"n_date\"] = stocks_df[\"n_date\"].astype(np.int32)\n",
    "    stocks_df[\"date\"] = stocks_df[\"n_date\"].apply(datetime.fromordinal)\n",
    "    return stocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculo de estadisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_stats(stocks_df):\n",
    "    stocks_df[\"average\"] = (stocks_df[\"close\"] + stocks_df[\"high\"] + stocks_df[\"low\"]) / 3.0\n",
    "    stocks_df[\"change_amount\"] = stocks_df[\"close\"] - stocks_df[\"open\"]\n",
    "    stocks_df[\"change_per\"] = stocks_df[\"change_amount\"] / stocks_df[\"average\"]\n",
    "    stocks_df[\"range\"] = (stocks_df[\"high\"] - stocks_df[\"low\"]) / stocks_df[\"average\"]\n",
    "    stocks_df[\"change_1_amount\"] = pd.Series(0.0)\n",
    "    stocks_df[\"change_1_amount\"][1:] = stocks_df[\"average\"][1:].values - stocks_df[\"average\"][:-1].values\n",
    "    stocks_df[\"change_1_per\"] = stocks_df[\"change_1_amount\"] / stocks_df[\"average\"]\n",
    "    return stocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajuste de datos para Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pivot_data(stocks_df, values=\"change_1_per\"):\n",
    "    clustering_data = stocks_df.pivot(index=\"Ticker\", columns=\"n_date\", values=values)\n",
    "    return clustering_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_data(data, n_clusters=8, normalize_data=False):\n",
    "    if normalize_data:\n",
    "        data = normalize(data.values, norm='l2', axis=1, copy=True)\n",
    "    cluster_model = KMeans(n_clusters=n_clusters)\n",
    "    prediction = cluster_model.fit_predict(data)\n",
    "    return prediction, cluster_model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_clusters(data_df, values=\"change_1_per\", n_clusters=8, normalize_data=False):\n",
    "    data = pivot_data(data_df, values)\n",
    "    prediction, model, c_data = cluster_data(data, n_clusters=n_clusters, normalize_data=normalize_data)\n",
    "    c_data = pd.DataFrame(c_data, index=data.index,columns=data.columns)\n",
    "    data[\"Cluster\"] = prediction\n",
    "    c_data[\"Cluster\"] = prediction\n",
    "    plt.figure\n",
    "    for cluster in np.unique(prediction):\n",
    "        plt.plot(model.cluster_centers_[cluster], \"o-\", alpha=0.5, linewidth=2)\n",
    "    plt.show()\n",
    "    for cluster in np.unique(prediction):\n",
    "        temp_cluster_data = c_data[c_data[\"Cluster\"]==cluster]\n",
    "        print \"Cluster: %s\" % cluster\n",
    "        print \"Members: %s\" % [\"%s: %s\"% (symbol, stock_dict[symbol]) for symbol in list(temp_cluster_data.index)]\n",
    "        plt.figure()\n",
    "        plt.title(\"Cluster#: %s\" % cluster)\n",
    "        plt.plot(model.cluster_centers_[cluster], \"o--\", alpha=0.5, linewidth=2)\n",
    "        for symbol in temp_cluster_data.index:\n",
    "            plt.plot(np.ravel(temp_cluster_data.loc[[symbol]].drop(\"Cluster\", 1).values),\n",
    "                     alpha=0.2, linewidth=2)\n",
    "            \n",
    "        plt.grid()\n",
    "        plt.show();\n",
    "    return prediction, model, c_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medicion de desempeno Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_error(prediction, model, c_data):\n",
    "    error_score = []\n",
    "    for counter in range(len(c_data)):\n",
    "        true_val = c_data.drop(\"Cluster\",1).values[counter]\n",
    "        center_val = model.cluster_centers_[c_data[\"Cluster\"][counter]]\n",
    "\n",
    "        error_score.append(np.average(np.abs(true_val - center_val)) / np.average(center_val))\n",
    "    \n",
    "    cluster_counts = c_data[\"Cluster\"].value_counts()\n",
    "    \n",
    "    return np.average(error_score), len(cluster_counts[cluster_counts==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_dict={\"ALFAA.MX\": \"ALFA.A\",\n",
    "            \"ALPEKA.MX\": \"ALPEK.A\",\n",
    "            \"ALSEA.MX\": \"ALSEA\",\n",
    "            \"AMXL.MX\": \"AMX.L\",\n",
    "            \"ASURB.MX\": \"ASUR.B\",\n",
    "            \"BIMBOA.MX\": \"BIMBO.A\",\n",
    "            \"BOLSAA.MX\": \"BOLSA.A\",\n",
    "            \"CEMEXCPO.MX\": \"CEMEX.CPO\",\n",
    "            \"COMERCIUBC.MX\": \"COMERCI.UBC\",\n",
    "            \"ELEKTRA.MX\": \"ELEKTRA\",\n",
    "            \"GAPB.MX\": \"GAP.B\",\n",
    "            \"GENTERA.MX\": \"GENTERA\",\n",
    "            \"GFINBURO.MX\": \"GFINBUR.O\",\n",
    "            \"GFNORTEO.MX\": \"GFNORTE.O\",\n",
    "            \"GFREGIOO.MX\": \"GFREGIO.O\",\n",
    "            \"GMEXICOB.MX\": \"GMEXICO.B\",\n",
    "            \"GRUMAB.MX\": \"GRUMA.B\",\n",
    "            \"GSANBORB-1.MX\": \"GSANBOR.B-1\",\n",
    "            \"ICA.MX\": \"ICA\",\n",
    "            \"ICHB.MX\": \"ICH.B\",\n",
    "            \"IENOVA.MX\": \"IENOVA\",\n",
    "            \"KIMBERA.MX\": \"KIMBER.A\",\n",
    "            \"KOFL.MX\": \"KOFL\",\n",
    "            \"LABB.MX\": \"LAB.B\",\n",
    "            \"LALAB.MX\": \"LALA.B\",\n",
    "            \"LIVEPOLC-1.MX\": \"LIVEPOL.C-1\",\n",
    "            \"MEXCHEM.MX\": \"MEXCHEM\",\n",
    "            \"OHLMEX.MX\": \"OHLMEX\",\n",
    "            \"PINFRA.MX\": \"PINFRA\",\n",
    "            \"SANMEXB.MX\": \"SANMEX.B\",\n",
    "            \"TLEVISACPO.MX\": \"TLEVISA.CPO\",\n",
    "            \"WALMEX.MX\": \"WALMEX\",\n",
    "           }\n",
    "symbols = stock_dict.keys()\n",
    "names = stock_dict.values()\n",
    "\n",
    "stocks_data = pd.DataFrame(symbols, columns=[\"Ticker\"])\n",
    "stocks_data[\"NAIC\"] = names\n",
    "stocks_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for symbol in stocks_data[\"Ticker\"]:\n",
    "    temp_data = download_data(symbol)\n",
    "    process_date(temp_data)\n",
    "    calculate_stats(temp_data)\n",
    "    temp_data[\"Ticker\"] = symbol\n",
    "    temp_list.append(temp_data)\n",
    "\n",
    "stocks_df = pd.concat(temp_list)\n",
    "stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering_data = pivot_data(stocks_df, values=\"change_amount\")\n",
    "clustering_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_data = normalize(clustering_data.values, axis=1)\n",
    "norm_data = pd.DataFrame(norm_data)\n",
    "for item in norm_data.values:\n",
    "    plt.plot(item)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction, model, data = cluster_data(clustering_data, n_clusters=8, normalize_data=True)\n",
    "print \"Cluster Count: %s\" % len(np.unique(prediction))\n",
    "clustering_data[\"Cluster\"] = prediction\n",
    "clustering_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction, model, c_data = visualize_clusters(stocks_df, values=\"change_amount\", n_clusters=8, normalize_data=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "measure_error(prediction, model, c_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busqueda del numero optimo de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_clusters = 30\n",
    "feature = \"average\"\n",
    "clustering_data = pivot_data(stocks_df, values=feature)\n",
    "clustering_data[\"Cluster\"] = pd.Series()\n",
    "for normalize_data in [True, False]:\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    plt.title(\"K-Means - Feature: %s Normalized: %s\" % (feature, normalize_data))\n",
    "    axes_1 = fig.add_subplot(111)\n",
    "    axes_2 = axes_1.twinx()\n",
    "    score_error_list = []\n",
    "    failed_clusters_list = []\n",
    "    \n",
    "    for n_clusters in range(2,max_clusters):\n",
    "        prediction, model, data = cluster_data(clustering_data.drop(\"Cluster\",1), n_clusters=n_clusters,\n",
    "                                               normalize_data=normalize_data)\n",
    "        data = pd.DataFrame(data, index=clustering_data.index,columns=clustering_data.drop(\"Cluster\",1).columns)\n",
    "        data[\"Cluster\"] = prediction\n",
    "        score_error, failed_clusters =  measure_error(prediction, model, data)\n",
    "        score_error_list.append(score_error)\n",
    "        failed_clusters_list.append(failed_clusters)\n",
    "    axes_1.plot(range(2,max_clusters), score_error_list, \"ro-\", label = \"Average Error\")\n",
    "    axes_2.plot(range(2,max_clusters), failed_clusters_list, \"bo-\", label = \"Failed Cluster\")\n",
    "    \n",
    "    axes_1.grid()\n",
    "    axes_1.legend(loc = \"lower center\")\n",
    "    axes_2.legend(loc = \"upper center\")\n",
    "    axes_1.set_ylabel(\"Average Error\")\n",
    "    axes_2.set_ylabel(\"Failed Cluster\")\n",
    "    axes_1.set_xlabel(\"Clusters\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
